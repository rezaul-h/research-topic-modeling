{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145314,
     "status": "ok",
     "timestamp": 1645555325616,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "_6XVbSaEWozm",
    "outputId": "ef0ef771-2e19-4dee-87f4-5d4b078e95c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8071,
     "status": "ok",
     "timestamp": 1645555333669,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "bsy1YqVTWlJN",
    "outputId": "93be73a1-1b58-4580-8082-62fb69c3435a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 6.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=dd3fb1991c6da747026b0b554e5212a0be34a0aa346787c7863373ce219dbf0f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "!pip install langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miQ9PKCsWlFl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from langdetect import detect\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1645555335164,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "iRadgzizWk9U",
    "outputId": "fe042915-f606-47a7-a016-5f17167e3303"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2ea08059-01be-4d28-98c6-9939e9708abb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Analysis of PDEs</th>\n",
       "      <th>Applications</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <th>Astrophysics of Galaxies</th>\n",
       "      <th>Computation and Language</th>\n",
       "      <th>Computer Vision and Pattern Recognition</th>\n",
       "      <th>Cosmology and Nongalactic Astrophysics</th>\n",
       "      <th>Data Structures and Algorithms</th>\n",
       "      <th>Differential Geometry</th>\n",
       "      <th>Earth and Planetary Astrophysics</th>\n",
       "      <th>Fluid Dynamics</th>\n",
       "      <th>Information Theory</th>\n",
       "      <th>Instrumentation and Methods for Astrophysics</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Materials Science</th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Number Theory</th>\n",
       "      <th>Optimization and Control</th>\n",
       "      <th>Representation Theory</th>\n",
       "      <th>Robotics</th>\n",
       "      <th>Social and Information Networks</th>\n",
       "      <th>Statistics Theory</th>\n",
       "      <th>Strongly Correlated Electrons</th>\n",
       "      <th>Superconductivity</th>\n",
       "      <th>Systems and Control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824</td>\n",
       "      <td>a ever-growing datasets inside observational a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3094</td>\n",
       "      <td>we propose the framework considering optimal $...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8463</td>\n",
       "      <td>nanostructures with open shell transition meta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2082</td>\n",
       "      <td>stars are self-gravitating fluids inside which...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8687</td>\n",
       "      <td>deep neural perception and control networks ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea08059-01be-4d28-98c6-9939e9708abb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2ea08059-01be-4d28-98c6-9939e9708abb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2ea08059-01be-4d28-98c6-9939e9708abb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     id  ... Systems and Control\n",
       "0  1824  ...                   0\n",
       "1  3094  ...                   0\n",
       "2  8463  ...                   0\n",
       "3  2082  ...                   0\n",
       "4  8687  ...                   0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/content/drive/MyDrive/Colab Notebooks/research topic prediction/\"\n",
    "df = pd.read_csv(path+ \"data/Train.csv\") #read trainning data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1645555336136,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "LAUO8aQ6oS6t",
    "outputId": "6a6f84de-b387-40ba-9214-8f9a9b4b7b7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1b141f48-c99b-42f5-8682-968626132420\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Statistics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9409</td>\n",
       "      <td>fundamental frequency (f0) approximation from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17934</td>\n",
       "      <td>this large-scale study, consisting of 24.5 mil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16071</td>\n",
       "      <td>we present a stability analysis of the plane c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16870</td>\n",
       "      <td>we construct finite time blow-up solutions to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10496</td>\n",
       "      <td>planetary nebulae (pne) constitute an importan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b141f48-c99b-42f5-8682-968626132420')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1b141f48-c99b-42f5-8682-968626132420 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1b141f48-c99b-42f5-8682-968626132420');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      id  ... Statistics\n",
       "0   9409  ...          1\n",
       "1  17934  ...          1\n",
       "2  16071  ...          0\n",
       "3  16870  ...          0\n",
       "4  10496  ...          0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df =  pd.read_csv('/content/drive/MyDrive/Colab Notebooks/research topic prediction/data/Test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1645555336140,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "y2O0ZGAIZ1It",
    "outputId": "132a003c-a3d6-4833-bec8-9ced7ac216dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (14004, 31)\n",
      "Columns are: Index(['id', 'ABSTRACT', 'Computer Science', 'Mathematics', 'Physics',\n",
      "       'Statistics', 'Analysis of PDEs', 'Applications',\n",
      "       'Artificial Intelligence', 'Astrophysics of Galaxies',\n",
      "       'Computation and Language', 'Computer Vision and Pattern Recognition',\n",
      "       'Cosmology and Nongalactic Astrophysics',\n",
      "       'Data Structures and Algorithms', 'Differential Geometry',\n",
      "       'Earth and Planetary Astrophysics', 'Fluid Dynamics',\n",
      "       'Information Theory', 'Instrumentation and Methods for Astrophysics',\n",
      "       'Machine Learning', 'Materials Science', 'Methodology', 'Number Theory',\n",
      "       'Optimization and Control', 'Representation Theory', 'Robotics',\n",
      "       'Social and Information Networks', 'Statistics Theory',\n",
      "       'Strongly Correlated Electrons', 'Superconductivity',\n",
      "       'Systems and Control'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#training data's share and name of columns\n",
    "print('Dataset size:',df.shape)\n",
    "print('Columns are:',df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcXTTjlQZ_cR"
   },
   "outputs": [],
   "source": [
    "\n",
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "new_line_pattern = re.compile(r\"\\n+\\S*\")\n",
    "\n",
    "contractions = {\n",
    "    \"ain't\": \"are not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he shall have / he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"I would\",\n",
    "    \"i'd've\": \"I would have\",\n",
    "    \"i'll\": \"I will\",\n",
    "    \"i'll've\": \"I will have\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that had\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59ThjgqZaKQ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_url(string):\n",
    "    return url_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9ew-jaNaPMV"
   },
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "\n",
    "    # Remove urls\n",
    "    message = remove_url(message)  \n",
    "\n",
    "    # Change new line to dot\n",
    "    message = new_line_pattern.sub(r'.', message)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    message = remove_punctuation(message)\n",
    "    \n",
    "    # Remove start and end whitespace\n",
    "    message = message.strip()\n",
    "    \n",
    "    # Make multiple spaces become a single space\n",
    "    message = ' '.join(message.split())\n",
    "    \n",
    "    # Lower case the message\n",
    "    message = message.lower()\n",
    "    \n",
    "    return message\n",
    "\n",
    "df['cleaned_text'] = df.apply(lambda row: clean_message(row['ABSTRACT']), axis=1)            #cleaning training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRDat0RfjdgB"
   },
   "outputs": [],
   "source": [
    "test_df['cleaned_text'] = test_df.apply(lambda row: clean_message(row['ABSTRACT']), axis=1) #cleaning test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1645555337360,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "Z30ItJo4jxh1",
    "outputId": "4999fa78-4240-4fe0-b8dc-d6f7708cb787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning STORY\n",
      "this largescale study consisting of 245 million hand hygiene opportunities spanning 19 distinct facilities inside 10 different states uses linear predictive models to expose factors that may affect hand hygiene compliance we examine a use of features such as temperature relative humidity influenza severity daynight shift federal holidays and a presence of new residents inside predicting daily hand hygiene compliance a results suggest that colder temperatures and federal holidays have an adverse effect on hand hygiene compliance rates and that individual cultures and attitudes regarding hand hygiene seem to exist among facilities\n",
      "After cleaning story\n",
      "this large-scale study, consisting of 24.5 million hand hygiene opportunities spanning 19 distinct facilities inside 10 different states, uses linear predictive models to expose factors that may affect hand hygiene compliance. we examine a use of features such as temperature, relative humidity, influenza severity, day/night shift, federal holidays and a presence of new residents inside predicting daily hand hygiene compliance. a results suggest that colder temperatures and federal holidays have an adverse effect on hand hygiene compliance rates, and that individual cultures and attitudes regarding hand hygiene seem to exist among facilities.\n"
     ]
    }
   ],
   "source": [
    "print(\"before cleaning STORY\")\n",
    "print(test_df.ABSTRACT[1])\n",
    "print(\"After cleaning story\")\n",
    "print(test_df.cleaned_text[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1645555337361,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "KOhy4JtuaTRZ",
    "outputId": "9b4c081b-4cfe-47b9-9a22-40035726a28a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning STORY\n",
      "we propose the framework considering optimal tmatchings excluding a prescribed tfactors inside bipartite graphs a proposed framework was the generalization of a nonbipartite matching problem and includes several problems such as a trianglefree 2matching squarefree 2matching even factor and arborescence problems inside this paper we demonstrate the unified understanding of these problems by commonly extending previous important results we solve our problem under the reasonable assumption which was sufficiently broad to include a specific problems listed above we first present the minmax theorem and the combinatorial algorithm considering a unweighted version we then provide the linear programming formulation with dual integrality and the primaldual algorithm considering a weighted version the key ingredient of a proposed algorithm was the technique to shrink forbidden structures which corresponds to a techniques of shrinking odd cycles triangles squares and directed cycles inside edmonds blossom algorithm the trianglefree 2matching algorithm the squarefree 2matching algorithm and an arborescence algorithm respectively\n",
      "After cleaning story\n",
      "we propose the framework considering optimal $t$-matchings excluding a prescribed $t$-factors inside bipartite graphs. a proposed framework was the generalization of a nonbipartite matching problem and includes several problems, such as a triangle-free $2$-matching, square-free $2$-matching, even factor, and arborescence problems. inside this paper, we demonstrate the unified understanding of these problems by commonly extending previous important results. we solve our problem under the reasonable assumption, which was sufficiently broad to include a specific problems listed above. we first present the min-max theorem and the combinatorial algorithm considering a unweighted version. we then provide the linear programming formulation with dual integrality and the primal-dual algorithm considering a weighted version. the key ingredient of a proposed algorithm was the technique to shrink forbidden structures, which corresponds to a techniques of shrinking odd cycles, triangles, squares, and directed cycles inside edmonds' blossom algorithm, the triangle-free $2$-matching algorithm, the square-free $2$-matching algorithm, and an arborescence algorithm, respectively.\n"
     ]
    }
   ],
   "source": [
    "print(\"before cleaning STORY\")\n",
    "print(df.cleaned_text[1])\n",
    "print(\"After cleaning story\")\n",
    "print(df.ABSTRACT[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIb1G5sjaimt"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Remove stop words from training data\n",
    "df['cleaned_text'] = df['cleaned_text'].str.split().apply(lambda x: [word for word in x if word not in stop_words]).apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jk1Wn9vAj6VL"
   },
   "outputs": [],
   "source": [
    "# Remove stop words from test data\n",
    "test_df['cleaned_text'] = test_df['cleaned_text'].str.split().apply(lambda x: [word for word in x if word not in stop_words]).apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1645555351254,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "YIkVGoFMkBr2",
    "outputId": "e195a56b-0b42-4134-81d3-ca8e1309715b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removieing stopwords:  this large-scale study, consisting of 24.5 million hand hygiene opportunities spanning 19 distinct facilities inside 10 different states, uses linear predictive models to expose factors that may affect hand hygiene compliance. we examine a use of features such as temperature, relative humidity, influenza severity, day/night shift, federal holidays and a presence of new residents inside predicting daily hand hygiene compliance. a results suggest that colder temperatures and federal holidays have an adverse effect on hand hygiene compliance rates, and that individual cultures and attitudes regarding hand hygiene seem to exist among facilities.\n",
      "After removieing stopwords:  largescale study consisting 245 million hand hygiene opportunities spanning 19 distinct facilities inside 10 different states uses linear predictive models expose factors may affect hand hygiene compliance examine use features temperature relative humidity influenza severity daynight shift federal holidays presence new residents inside predicting daily hand hygiene compliance results suggest colder temperatures federal holidays adverse effect hand hygiene compliance rates individual cultures attitudes regarding hand hygiene seem exist among facilities\n"
     ]
    }
   ],
   "source": [
    "print(\"before removieing stopwords: \",test_df['ABSTRACT'][1])\n",
    "print(\"After removieing stopwords: \",test_df['cleaned_text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1645555351255,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "pPfhxGRZawe0",
    "outputId": "6b3cdf4d-01d5-400d-b2fc-bcd5af387870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removieing stopwords:  we propose the framework considering optimal $t$-matchings excluding a prescribed $t$-factors inside bipartite graphs. a proposed framework was the generalization of a nonbipartite matching problem and includes several problems, such as a triangle-free $2$-matching, square-free $2$-matching, even factor, and arborescence problems. inside this paper, we demonstrate the unified understanding of these problems by commonly extending previous important results. we solve our problem under the reasonable assumption, which was sufficiently broad to include a specific problems listed above. we first present the min-max theorem and the combinatorial algorithm considering a unweighted version. we then provide the linear programming formulation with dual integrality and the primal-dual algorithm considering a weighted version. the key ingredient of a proposed algorithm was the technique to shrink forbidden structures, which corresponds to a techniques of shrinking odd cycles, triangles, squares, and directed cycles inside edmonds' blossom algorithm, the triangle-free $2$-matching algorithm, the square-free $2$-matching algorithm, and an arborescence algorithm, respectively.\n",
      "After removieing stopwords:  propose framework considering optimal tmatchings excluding prescribed tfactors inside bipartite graphs proposed framework generalization nonbipartite matching problem includes several problems trianglefree 2matching squarefree 2matching even factor arborescence problems inside paper demonstrate unified understanding problems commonly extending previous important results solve problem reasonable assumption sufficiently broad include specific problems listed first present minmax theorem combinatorial algorithm considering unweighted version provide linear programming formulation dual integrality primaldual algorithm considering weighted version key ingredient proposed algorithm technique shrink forbidden structures corresponds techniques shrinking odd cycles triangles squares directed cycles inside edmonds blossom algorithm trianglefree 2matching algorithm squarefree 2matching algorithm arborescence algorithm respectively\n"
     ]
    }
   ],
   "source": [
    "print(\"before removieing stopwords: \",df['ABSTRACT'][1])\n",
    "print(\"After removieing stopwords: \",df['cleaned_text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1558,
     "status": "ok",
     "timestamp": 1645555352765,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "Jhl7SZova48W",
    "outputId": "8b234deb-e180-43dc-e71f-f2667c9fdf09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inside', 45530),\n",
       " ('considering', 27427),\n",
       " ('method', 7894),\n",
       " ('data', 7889),\n",
       " ('model', 7766),\n",
       " ('help', 5580),\n",
       " ('show', 5566),\n",
       " ('learning', 5537),\n",
       " ('results', 5271),\n",
       " ('paper', 4933)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequent words from training data\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df[\"cleaned_text\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1645555353658,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "36IZKrQFkevk",
    "outputId": "504621ae-d694-49ca-827a-1f4f53a6e673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inside', 19667),\n",
       " ('considering', 11606),\n",
       " ('method', 3460),\n",
       " ('model', 3458),\n",
       " ('data', 3359),\n",
       " ('learning', 2359),\n",
       " ('help', 2350),\n",
       " ('show', 2329),\n",
       " ('results', 2172),\n",
       " ('paper', 2143)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequent words from test data\n",
    "\n",
    "test_cnt = Counter()\n",
    "for text in test_df[\"cleaned_text\"].values:\n",
    "    for word in text.split():\n",
    "        test_cnt[word] += 1\n",
    "        \n",
    "test_cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOL4eVU44ELl"
   },
   "outputs": [],
   "source": [
    "#rare words removal from training data\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1645557606274,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "VNshplYZ4FWA",
    "outputId": "0ba89af9-3571-4fac-b92c-f8c52b52d57f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diverged',\n",
       " 'extremeconditions',\n",
       " 'fe112te',\n",
       " 'fe1yte',\n",
       " 'higgstype',\n",
       " 'interpolationbased',\n",
       " 'reparameterised',\n",
       " 'spinresolved',\n",
       " 'tmathrmc48k',\n",
       " 'tmathrmn63k'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAREWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RysU4Zq8a9Tl"
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda text: remove_rarewords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WQsb2mqkM3w"
   },
   "outputs": [],
   "source": [
    "#rare words removal from test data\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in test_cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "test_df[\"cleaned_text\"] = test_df[\"cleaned_text\"].apply(lambda text: remove_rarewords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645555355757,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "hfC7mkFpbCTV",
    "outputId": "22ba995f-b288-4d77-d62e-3ad3d2d42eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before lemmatization :  propose framework considering optimal tmatchings excluding prescribed tfactors inside bipartite graphs proposed framework generalization nonbipartite matching problem includes several problems trianglefree 2matching squarefree 2matching even factor arborescence problems inside paper demonstrate unified understanding problems commonly extending previous important results solve problem reasonable assumption sufficiently broad include specific problems listed first present minmax theorem combinatorial algorithm considering unweighted version provide linear programming formulation dual integrality primaldual algorithm considering weighted version key ingredient proposed algorithm technique shrink forbidden structures corresponds techniques shrinking odd cycles triangles squares directed cycles inside edmonds blossom algorithm trianglefree 2matching algorithm squarefree 2matching algorithm arborescence algorithm respectively\n"
     ]
    }
   ],
   "source": [
    "print(\"Before lemmatization : \",df['cleaned_text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111680,
     "status": "ok",
     "timestamp": 1645555467427,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "Oty-9phtbGIV",
    "outputId": "ebaa51a3-981f-4520-ac5b-aae029a9ee94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After lemmatization :  propose framework consider optimal tmatchings exclude prescribed tfactors inside bipartite graph propose framework generalization nonbipartite match problem include several problem trianglefree 2matching squarefree 2matching even factor arborescence problem inside paper demonstrate unify understanding problem commonly extend previous important result solve problem reasonable assumption sufficiently broad include specific problem list first present minmax theorem combinatorial algorithm consider unweighted version provide linear program formulation dual integrality primaldual algorithm consider weighted version key ingredient propose algorithm technique shrink forbidden structure correspond technique shrink odd cycle triangle square direct cycle inside edmonds blossom algorithm trianglefree 2matching algorithm squarefree 2matching algorithm arborescence algorithm respectively\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda text: lemmatize_words(text))       #lemmiatize training data\n",
    "\n",
    "print(\"After lemmatization : \",df['cleaned_text'][1])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Wl3L9KPk5L2"
   },
   "outputs": [],
   "source": [
    "test_df[\"cleaned_text\"] = test_df[\"cleaned_text\"].apply(lambda text: lemmatize_words(text)) #lemmiatize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpjyYi9dE94i"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/content/drive/MyDrive/Colab Notebooks/research topic prediction/data/train_df.csv', index=False)\n",
    "test_df.to_csv('/content/drive/MyDrive/Colab Notebooks/research topic prediction/data/test_df.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "executionInfo": {
     "elapsed": 1108,
     "status": "ok",
     "timestamp": 1645558139922,
     "user": {
      "displayName": "the rexa",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdFYe5N7GieR8ehC_ceOpXkSut32xHin01-ukg=s64",
      "userId": "02346515912121062735"
     },
     "user_tz": -360
    },
    "id": "X5KYVLNX6BOf",
    "outputId": "5c76047f-f2c3-4f0b-e83c-f02a54d55670"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ae3a5cc5-f5f4-41e6-b357-4c42883f870a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Analysis of PDEs</th>\n",
       "      <th>Applications</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <th>Astrophysics of Galaxies</th>\n",
       "      <th>Computation and Language</th>\n",
       "      <th>Computer Vision and Pattern Recognition</th>\n",
       "      <th>Cosmology and Nongalactic Astrophysics</th>\n",
       "      <th>Data Structures and Algorithms</th>\n",
       "      <th>Differential Geometry</th>\n",
       "      <th>Earth and Planetary Astrophysics</th>\n",
       "      <th>Fluid Dynamics</th>\n",
       "      <th>Information Theory</th>\n",
       "      <th>Instrumentation and Methods for Astrophysics</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Materials Science</th>\n",
       "      <th>Methodology</th>\n",
       "      <th>Number Theory</th>\n",
       "      <th>Optimization and Control</th>\n",
       "      <th>Representation Theory</th>\n",
       "      <th>Robotics</th>\n",
       "      <th>Social and Information Networks</th>\n",
       "      <th>Statistics Theory</th>\n",
       "      <th>Strongly Correlated Electrons</th>\n",
       "      <th>Superconductivity</th>\n",
       "      <th>Systems and Control</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824</td>\n",
       "      <td>a ever-growing datasets inside observational a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>evergrowing datasets inside observational astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3094</td>\n",
       "      <td>we propose the framework considering optimal $...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>propose framework consider optimal tmatchings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8463</td>\n",
       "      <td>nanostructures with open shell transition meta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nanostructures open shell transition metal mol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2082</td>\n",
       "      <td>stars are self-gravitating fluids inside which...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>star selfgravitating fluid inside pressure buo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8687</td>\n",
       "      <td>deep neural perception and control networks ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deep neural perception control network likely ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae3a5cc5-f5f4-41e6-b357-4c42883f870a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ae3a5cc5-f5f4-41e6-b357-4c42883f870a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ae3a5cc5-f5f4-41e6-b357-4c42883f870a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     id  ...                                       cleaned_text\n",
       "0  1824  ...  evergrowing datasets inside observational astr...\n",
       "1  3094  ...  propose framework consider optimal tmatchings ...\n",
       "2  8463  ...  nanostructures open shell transition metal mol...\n",
       "3  2082  ...  star selfgravitating fluid inside pressure buo...\n",
       "4  8687  ...  deep neural perception control network likely ...\n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/research topic prediction/data/train_df.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
